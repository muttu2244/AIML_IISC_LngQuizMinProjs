{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aisha-partha/AIMLOps-Assignments/blob/main/M5_AST_04_Transformer_Encoder_C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNgLag1Euy3H"
      },
      "source": [
        "# Advanced Certification Programme in AI and MLOps\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 4: Transformer Encoders, Self Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdtrlAhvIHY"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* understand the big picture of transformers\n",
        "* understand the concept of self attention\n",
        "* explore transformer encoder and positional embedding\n",
        "* train an encoder-only transformer model for text classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Big Picture of Transformer"
      ],
      "metadata": {
        "id": "Tv8TQrtfwaNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/M5%20AST%205%20Big%20Picture.png\" width=800px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "ni6YCBwE7d_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above is the entire architecture of transformer. A TextVectorization layer, Embedding layer, an Encoder and a Decoder.\n",
        "\n",
        "Transformer architecture follows an encoder-decoder structure. The encoder, on the left-hand side, is tasked with mapping an input sequence to a sequence of continuous representations; the decoder, on the right-hand side, receives the output of the encoder together with the decoder output at the previous time step to generate an output sequence."
      ],
      "metadata": {
        "id": "AxzUg64Jdv-s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformer architecture was originally designed for translation. In the encoder, the attention layers can use all the words in a sentence (since, as we just saw, the translation of a given word can be dependent on what is after as well as before it in the sentence). The decoder, however, works sequentially and can only pay attention to the words in the sentence that it has already translated (so, only the words before the word currently being generated). For example, when we have predicted the first three words of the translated target, we give them to the decoder which then uses all the inputs of the encoder to try to predict the fourth word.\n",
        "\n",
        "To speed things up during training (when the model has access to target sentences), the decoder is fed the whole target, but it is not allowed to use future words (if it had access to the word at position 2 when trying to predict the word at position 2, the problem would not be very hard!). For instance, when trying to predict the fourth word, the attention layer will only have access to the words in positions 1 to 3."
      ],
      "metadata": {
        "id": "rgVPmcTjnORs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder-only Transformer:**\n",
        "\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "<img src= \"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/M5_AST_05_Image1_Transformer.png\" width=900px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "VtUillZR7eEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this assignment decoder will not form the topic of discussion, the main focus will be on the Transformer Encoder.\n",
        "This has been discussed in detail in the later sections of this notebook."
      ],
      "metadata": {
        "id": "geRywC9LeHjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Description"
      ],
      "metadata": {
        "id": "ECysu18IoMaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **IMDb Movie Reviews dataset** is a binary sentiment analysis dataset consisting of 50,000 reviews from the Internet Movie Database (IMDb) labeled as *positive* or *negative*. The dataset contains an even number of positive and negative reviews."
      ],
      "metadata": {
        "id": "XLrl_aUaoPam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is processed and used in the later sections of this notebook."
      ],
      "metadata": {
        "id": "KzZ2UaHyoS6z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z4UlAXa6hWqZ"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2304896\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8mAxYYRyhWq3"
      },
      "outputs": [],
      "source": [
        "#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"9916583736\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32ab745d-ac09-4e84-8c37-d30f89ffeabb",
        "id": "2P_-RHtFhWq3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2304896&recordId=6349\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"M5_AST_04_Transformer_Encoder_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "#  ipython.magic(\"sx pip3 install torch\")\n",
        "\n",
        "    ipython.magic(\"sx curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\")\n",
        "    ipython.magic(\"sx tar -xvzf aclImdb_v1.tar.gz\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "\n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "\n",
        "    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id,\n",
        "              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:\n",
        "        print(r[\"err\"])\n",
        "        return None\n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "\n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional\n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "\n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "\n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer():\n",
        "  try:\n",
        "    if not Answer:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Answer\n",
        "  except NameError:\n",
        "    print (\"Please answer Question\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def getId():\n",
        "  try:\n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup\n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup()\n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RH8Ecq9sbYU"
      },
      "source": [
        "### Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, pathlib, shutil, random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization, Embedding, Dense\n",
        "from tensorflow.keras.utils import text_dataset_from_directory"
      ],
      "metadata": {
        "id": "qnUhfGmx9cup"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Part A** : Text Pre-processing Before Transformer Block"
      ],
      "metadata": {
        "id": "4F75jcgTzupQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing the dataset using TextVectorization layer of keras"
      ],
      "metadata": {
        "id": "flOZCU1JQNYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation"
      ],
      "metadata": {
        "id": "jn2d9qngV5K7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pre-processed version of the IMDB dataset provided by Keras was used in the previous assignments.\n",
        "\n",
        "Originally IMDB dataset contains the *train* and the *test* folders.\n",
        "Here, the original dataset will be used and pre-processing related to it will be explored."
      ],
      "metadata": {
        "id": "V_vp0iDhV5K7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List subdirectories\n",
        "!cd aclImdb && ls -d */"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b6eb2d-a8e4-41cb-f9e6-808702a59a94",
        "id": "w9AUjmPKV5K7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test/  train/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unnecessary folder\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "6EGl3jHuV5K8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check a sample review\n",
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e9e220-353e-48a0-ec18-ef82c2140f23",
        "id": "aaz8LeVpV5K8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a validation directory and move 20% of the train data to it"
      ],
      "metadata": {
        "id": "EpQAM63FV5K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# move 20% of the training data to the validation folder\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    # random.Random(1337).shuffle(files) # We should shuffle. Only commenting for demonstration\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ],
      "metadata": {
        "id": "YKcPti-aV5K8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create batches of data using `text_dataset_from_directory`"
      ],
      "metadata": {
        "id": "guEKB2skV5K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset using utility\n",
        "batch_size = 32\n",
        "\n",
        "# Q: Name other such utilities seen earlier ?\n",
        "train_ds = text_dataset_from_directory(\"aclImdb/train\", batch_size=batch_size)\n",
        "\n",
        "val_ds = text_dataset_from_directory(\"aclImdb/val\", batch_size=batch_size)\n",
        "\n",
        "test_ds = text_dataset_from_directory(\"aclImdb/test\", batch_size=batch_size)\n",
        "\n",
        "# Extracting only the review text(not labels); to be used later to adapt the TextVec layer\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)             # lambda x, y: x  --> replace x,y with x. That is remove labels, just keep text data.\n"
      ],
      "metadata": {
        "id": "oEKMaWJ6V5K9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c658ee5-1b30-4348-faf0-91547042c946"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(train_ds.take(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JBsqc1cnAYm",
        "outputId": "2f1ce0eb-eb90-4a28-da17-82179c6f19d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "  array([b\"A LAUREL & HARDY Comedy Short. The Boys arrive to sweep the chimneys at the home of Professor Noodle, a mad scientist who's just perfected his rejuvenation serum. Stan & Ollie proceed with their DIRTY WORK, spreading destruction inside the house and on the roof. Then the Professor wants to try out his new potion...<br /><br />A very funny little film. The ending is a bit abrupt, but much of the slapstick leading up to it is terrific. Especially good is Stan & Ollie's contest of wills at opposite ends of the chimney. That's Lucien Littlefield as the Professor.\",\n",
              "         b'An unusual take on time travel: instead of traveling to Earth\\'s past, the main trio get stuck in the past history of another planet. They beam down to this planet, whose sun is scheduled to go nova in 3 or 4 hours (that\\'s cutting it close!). In some kind of futuristic library, they meet Mr. Atoz (A to Z, get it? ha-ha) and his duplicates. It turns out, instead of escaping their planet\\'s destruction via space travel, the usual way, the inhabitants have all escaped into their planet\\'s various past time eras. Mr. Atoz uses a time machine to send people on their way after they make a selection (check out the discs we see here, another Trek prognostication of CDs and DVDs!). When Mr. Atoz prepares the machine (the Atavachron-what-sis), gallant Kirk hears a woman\\'s scream and runs into the planet\\'s version of Earth\\'s 17th century, where he gets into a sword fight and is arrested for witchery. There\\'s an eccentric but good performance here by the actress playing a female of ill repute in this time, using phrasing of the time (\"...you\\'re a bully fine coo.. Witch! Witch! They\\'ll burn ye...!\"). Spock & McCoy follow Kirk, but end up in an ice age, 5000 years earlier.<br /><br />Kirk manages to get back to the library first. The real story here is Spock\\'s reversion to the barbaric tendencies of his ancestors, the warlike Vulcans of 5000 years ago. This doesn\\'t really make sense, except that maybe this time machine is responsible for the change (even so, Spock & McCoy weren\\'t \\'prepared\\' by Atoz - oh, well; it also seems to me Spock was affected by the transition almost immediately - he mentions being from \\'millions of light years\\' away, instead of the correct hundreds or thousands - a gross error for a logical Vulcan). In any case, Spock really shows his nasty side here - forget \"Day of the Dove\" and remember \"This Side of Paradise\" - McCoy quickly finds out that his Vulcan buddy will not stand for any of his usual baiting and nearly gets his face rearranged. Spock also gets it on with Zarabeth, a comely female who had been exiled to this cold past as punishment (a couple of Trek novels were written about Spock\\'s son, the result of this union). All these scenes are eye-openers, a reminder of just how much Spock conceals or holds in. It\\'s also ironic that, only a few episodes earlier (\"Requiem for Methuselah\"), McCoy was pointing out to Spock how he would never know the pain of love - and now all this happens. Kirk, meanwhile, tussles with the elderly Atoz, who insists that Kirk head back to some past era (\"You are evidently a suicidal maniac\" - great stuff from actor Wolfe, last seen in \"Bread and Circuses\"). It all works out in the end, but, like I mentioned earlier, they cut it very close. A neat little Trek adventure, with a definite cosmic slant.',\n",
              "         b\"Evidently, not many people have seen this movie, because no one is posting any more comments. This is not a movie to be missed. After all, it has won the George Peabody award as well as the Humanitas award. Paul Winfield should have won an award for his awesome performance in this movie. Eugene Logan who was a co-writer on this made for TV movie also was part of another movie on humanity, or loss of it, by being a technical adviser to Truman Capote's movie the Glass House. This movie is now available on DVD. If anyone is interested, I will post another letter telling how it was that Eugene Logan came to be the technical adviser to a movie of such an amazing person as Truman Capote. Thanks for reading this and I hope you will find a way to view these two movies.\",\n",
              "         b\"This ABC straight-to-TV failure does absolutely no justice to the brilliant fantasy novel that is A Wrinkle in Time. Ms. Madeleine L'Engle brought children and adults alike into a magical, fantastical and original world like no author before her. This novel, the first in her 'time quartet', is a beautiful take on life, the universe, and time itself. Yet it is easy for any child or adolescent to understand. Its unwavering morals are prevalent throughout the book. This film adaptation can be seen as nothing but a mockery of Ms. L'Engle's work of art. Honestly, what were they thinking? The effects look cheap and ridiculous, the plot is mushy and uneven, the dialogue is far-fetched and just about every magical characteristic of the novel has been lost. This was a horrible attempt at bringing this book to the screen. I sincerely hope that someday an intelligent, worthy director (Guillermo del Toro, David Yates, Alfonso Cuar\\xc3\\xb3n) makes another attempt at bringing this book to the screen and understands it for what it truly is: a masterpiece. This adaptation can only be compared to boring, fake and cheap motel-room art which holds no ground and makes absolutely no impact on its audience.\",\n",
              "         b\"I am so happy and surprised that there is so much interest in this movie! Jack Frost was my introduction into the films produced and distributed by A-pix entertainment, and without exception, everything this company deals with is pure crap! First, and this is very important, never ever watch this movie sober! Why would you? Unlike many other entertaingly bad movies, this one I feel was made intentionally bad. I just can't get over how fake the snowman is, which is why its always shown only briefly, the way it moves is the best! This movie is Waaaaaaaaaaay better than the Michael Keaton piece of crap, becuz that was made too be a good movie, and that version is as bad as this.\",\n",
              "         b\"A movie about dealing with the problems with growing up and being true to yourself, Blue Juice is mind candy for those who like surfing and Cornwall. Sean Pertwee is the real star of this film, while the more famous Catherine Zeta Jones plays his girlfriend and Ewan Mcgregor plays his drug addicted pal.<br /><br />For those who don't like surfing or Cornwall in the slightest, you'll find that it takes a long time before the movie even hints at being interesting. The beginning is slow and spends too much time on long shots of only slightly interesting landscapes. Plus too many main characters leads to most of them being one dimensional. The plot is an interesting idea but because of the shallow characters you have no idea why they act in the situations they're put in.<br /><br />Only Ewan, Sean and Catherine's characters make this a film worth being on videotape, which is why it was only released on videotape in the US after Ewan and Catherine reached mainstream fame.\",\n",
              "         b\"This has to be the worst movie I have seen. Madsen fans don't be drawn into this like I was. He is only in it for a maximum of five minutes. This movie is so bad that the only reason why you would watch it is if all the rest of the movies on earth as well as t.v. had been destroyed.\",\n",
              "         b\"I just watched this movie and I've gotta say that with such a great premise and great talent this turkey just lays there!!! A friend lent me this movie and I watched with an open mind mainly because he had such high praise for the story. <br /><br />Well, the movie started off with Kevin Costner as a fighter pilot retiring... why? Why did they make him a fighter pilot? He was supposedly going to be hired by Anthony Quinn's character to be his new pilot... well, we never see Costner go near a plane for the rest of the movie! <br /><br />Costner runs into a Texan (James Gammon) selling a horse to a big Mexican businessman and Costner tags along for a ride. Without knowing what happened, Gammon is beat to near death and Costner drives him to the meeting, which happens to be with an associate of Quinn! But, nothing comes of it... nada, zilcho! Why did they have Gammon's character? Why did they have the horse sale with the Quinn associate if nothing was to come of it? <br /><br />Also, after they leave Costner for dead, they make Madeline Stowe's character become a whore, then she attacks one of Quinn's men that was paying for a turn... she stabs him with his own knife, and the next thing she's been moved to a convent! No explanation as to why she was moved, or when it was done!<br /><br />Too much talent wasted on such a weak script and poor editing!! I only watched this because a friend owned it and let me watch it... I'm going to throw it at him for the 2 hours I wasted of my life watching the blasted thing!\",\n",
              "         b'Slow and nice images changed one another, with sometimes annoying music (you know Bjork) in background, for the first 75% of the movie. If you did not have enough sleep, that\\'s a good time. <br /><br />But, in the last 20% of the movie director decides to bring idea of re-birth, re-incarnation or else, through S&M images: \"spiritual lovers\" are cutting each others bodies with knives. For me it was very much disturbing and actually changed general impression of blend of abstract art and images of modern Japanese mystery. <br /><br />Operator and director are great, but weird. <br /><br />Did not enjoy it at all.',\n",
              "         b'Typical De Palma movie made with lot\\'s of style and some scene\\'s that will bring you to the edge of your seat.<br /><br />Most certainly the thing that makes this movie better as the average thriller, is the style. It has some brilliantly edited scene\\'s and some scene\\'s that are truly nerve wrecking that will bring you to the edge of your seat. The best scene\\'s from the movie; The museum scene and the elevator murder. There are some mild erotic scene\\'s and the movies pace might not be fast enough for the casual viewer to fully appreciate this movie. So this movie might not be suitable for everybody.<br /><br />The story itself is also quite good but it really is the style that makes the movie work! It might be for the fans only but also casual viewers should appreciate the well build up tension in the movie.<br /><br />There are some nice character portrayed by a good cast. Michael Caine is an interesting casting choice and Angie Dickinson acts just as well as she is good looking (not bad for a 49-year old!).<br /><br />The musical score by Pino Donaggio is also typically De Palma like and suits the movie very well, just like his score for the other De Palma movie, \"Body Double\".<br /><br />Brilliant nerve wrecking thriller. I love De Palma!<br /><br />10/10',\n",
              "         b'The freedom of having your own Sea Going Power Boat, the excitement of going on underwater adventures a rugged,an\\'s man of an adventurer and lovely(and so well endowed!) assistants in fine Bikinis were all definite selling points for \"SEA HUNT\"(1958-61).<br /><br />Just what was the reason for producing a sort of sea going \"gun for hire\"* series. Let\\'s look closely now. There must be a some clues around.<br /><br />If we were to look back just a little, we see the RKO Radio Pictures production of UNDERWATER! (1955). It starred Jane Russell, Gilbert Roland, Richard Egan and Lori Nelson as a quartet of very attractive Scuba Diving Adventurers working on salvage in the Carribbean, including a Pre-Fidel Cuba. The film was moderately successful and was memorable not necessarily for its story as for the looks of the principals in swimming suits. Fine, shapely Women Folk in some really keen 2 piece bathing suits (Woo, woo, woo, woo!) are always a plus for the Guys; and the presence of rugged, athletic men folk displaying their best beefcake \"poses\" is equally pleasing to the Gals.<br /><br />And there is one element that is a true legacy of this old RKO Feature. It is on the Soundtrack contained in between the musical queues and themes. It is the Recording of \"It\\'s Cherry Pink and Apple Blossom White\", written by Louiguy and Jacques LaRue and performed by Damaso Perez Prado and His Orchestra.<br /><br />Anyone who hears this Insturmental or Song (with Lyrics)will not soon forget it. Its Carribbean Beat is so very lively and its rich use of the Brass Section of the Orchestra is Powerful and instantly renders instant impression and memory. The 45 RPM Record of this Song made it to the Top 10 most Popular Songs of the Week for many Saturday Evenings on NBC TV\\'s \"YOUR HIT PARADE\". We can\\'t remember just how many weeks nor just how high it got. (Maybe some one can fill us in on that one item, please!) So, we got back to \"SEA HUNT\" and its own odyssey in getting on \"the Tube\". The public had taken to UNDERWATER! all right, but would they go for a TV Series.<br /><br />ZIV TV Productions was getting a reputation for putting out a type of product that, for the most part, didn\\'t get signed on by the Networks for the multi-station hook-up treatment. But they had been having some great successes with Television Syndication.** By that we mean, offering a Series for Stations for showings on a one to a TV Station per each Market Area. (Much like the various Newspaper Syndicates \"sell\" Comic Strips to various Papers around the Country, and World, even.<br /><br />So, we got \\'Mike Nelson\\', himself, in the physical presence of Lloyd Bridges. Mr. Bridges had been around for approximately 15 years or so and had turned in some very memorable performances in mostly supporting and highly varying roles in a couple of Boston Blackie movies (with Chester Morris)to THEY STOOGE TO CONGA (3 Stooges 1943), SAHARA (also 1943), HOME OF THE BRAVE (1949) and THE WHISTLE AT EATON FALLS(1951).<br /><br />Lloyd brought a very convincing manner to his characterization, along with a fine, convincingly athletic physique, having the look of a guy who makes his living with his physical abilities. He took very well as the Diver\\'s Diver, whether it\\'s performing duties on board ship, or fathoms beneath the Sea.<br /><br />And Lloyd did take to the role quickly, but contrary to a lot of misinformation out there, he was not familiar with S.C.U.B.A.*** prior to landing this Mike Nelson gig. But the Athletic Mr. Bridges proved to be a quick learner, as so many of the close-up shots underwater revealed that there was no doubt about it, that it was Lloyd with the mask, the bubbler(air tank) and the flipper fins.<br /><br />Stories almost always involved the helping-out some client for pay, much like a Private Detective would. So what if the client was a lovely Lady who looked good in the Bathing Suit, all the better.<br /><br />Like so many of the other ZIV/UNITED ARTISTS TV Productions,\"SEA HUNT\" possessed a fine, haunting Opening Theme and Closing, along with some original incidental music and queues.<br /><br />At one time, I believe that \"SEA HUNT\" was the top syndicated TV Series, a success that ZIV Series had known before with the likes of \"SCIENCE FICTION THEATRE\"and \"HIGHWAY PATROL\". As far as the showing venue for this underwater saga, here in Chicago it was shown late night (after 10:30 P.M.) on WNBQ TV, Channel 5 (our NBC Affiliate, now known as WMAQ TV).<br /><br />And I can remember just who was the original sponsor in this particular market was. And there were even on scene commercials done by the Star! How well we can remember and visualize Lloyd as Mike Nelson, riding on his Power Boat. And as we were being invited to return the next week and watch \".....another adventure of \"SEA HUNT\", sponsored by the G. Heileman Brewing Company of LaCrosse, Wisconsin\\' the makers of Old Style Lager Beer!\", all while Mike was toasting us, raising an Old Style Bottle. (Shame on you, Mike! Drinking Beer on your moving Boat! We\\'re tellin\\' the Coast Guard!) Then, the Boat would leave the dock, accompanied by the Sea Hunt Theme and rolling the Credits.<br /><br />NOTE: * More figuratively than literal, Mike was for hire and things ran very much like a Deterctive Story.<br /><br />NOTE: ** ZIV\\'s Syndicated successes included \"SCIENCE FICTION THEATRE\", \"WEST POINT\"(and its clone \"MEN OF ANNAPOLIS\"), \"SEA HUNT\" and \"HIGHWAY PATROL\".<br /><br />NOTE*** And of course, SCUBA is a acronym for Self Contained Underwater Breathing Apparatus.',\n",
              "         b'1st watched 5/17/2002 - 3 out of 10(Dir-Ewald Andre Dupont): Fairly lame account of the Titanic disaster is the first filmed version of this much-heralded event. The replication of the disaster is not bad, but the drama around it is at some times silly, badly acted and way-too soap opera-like. The story is very much the same as the most recent Oscar-winning one except that we are shown how the crew tried to hide the actual disaster that was occurring until almost too late. Good for nostalgia purposes only and to get a feel for what James Cameron was competing against(barely\\xc2\\x85) in his recreation.',\n",
              "         b'This movie surprised me, it had good one-liners and laughs, + a nonstop action-packed storyline with tons of gun action and explosions. This movie surprisingly had a lot of good twists and turns. The plot is solid despite what others may think, it kept my interest the whole time right up till the very end. In conclusion; this is a great way for an action movie buff to spend time on.',\n",
              "         b'If the term itself were not geographically and semantically meaningless, one might well refer to \"Ned Kelly\" as an \"Australian Western.\" For the people Down Under, Ned Kelly was, apparently, a folk hero bandit akin to Robin Hood, Jesse James, Bonnie and Clyde, and Butch Cassidy and the Sundance Kid. The descendant of Irish immigrants, Kelly became a fugitive and an outlaw after he was falsely accused of shooting an Australian law officer, a crime for which his equally innocent mother was put into prison. To get back at the government for this mistreatment, Kelly, his brother Dan, and two other companions, became notorious bank robbers, winning over the hearts of many people in the countryside while striking a blow for justice in a land where Irish immigrants were often treated with disrespect and disdain by those who ran the country.<br /><br />Perhaps because we\\'ve encountered this \"gentleman bandit\" scenario so many times in the past, \"Ned Kelly\" feels awfully familiar and unoriginal as it pays homage to any number of the genre\\'s stereotypes and clich\\xc3\\xa9s on its way to the inevitable showdown. Ned is the typical heart-of-gold lawbreaker who kills only when he is forced to and, even then, only with the deepest regret. He also has the pulse of the common folk, as when, in the middle of a bank robbery, he returns a valuable watch to one of the customers, after one of his gang has so inconsiderately pilfered it. What movie on this particular subject hasn\\'t featured a scene like that? It\\'s acts of selective generosity like this, of course, that earn him the love and respect of all the little people who come to secretly admire anyone who can get away with sticking it to the powers-that-be and the status quo. Geoffrey Rush plays the typical bedeviled law enforcer who feels a personal stake in bringing down this upstart troublemaker who keeps getting away with tweaking the establishment. There\\'s even the inevitable episode in which one of the ladies being held up goes into the next room and has sex with one of the robbers, so turned on is she by the romantic derring-do of the criminal lifestyle. And the film is riddled with one hackneyed scene like this after another.<br /><br />Heath Ledger fails to distinguish himself in the title role, providing little in the way of substance to make his character either interesting or engaging. It doesn\\'t help that he has been forced to provide a droning voice-over narration that underlines the sanctimoniousness and pretentiousness of both the character and the film.<br /><br />\"Ned Kelly\" might serve a function of sorts as a lesson in Australian history, but as an entertainment, it\\'s just the same old story told with different accents.',\n",
              "         b'Ah, true memories. I lived in Holland at the time and looked eagerly forward to it every Sunday evening and later Tuesdays. I saw it during my 14-16s. Very good for my (at the time school-)English, as Dutch TV provides subtitles for other languages, except for kiddies shows nowadays. So you would hear the original voices and language. - The best series were the first three ones and then after the third series, the great character, Nazi Von Gelb, who was such a formidable enemy, disappeared from the series (I don\\'t think they ever really caught him, he always escaped, leaving room to have him appear again in a next story) because evidently the series also was distributed to Germany, and a Nazi enemy wouldn\\'t go over very well! Too bad, because Geoffrey Toone did such a wonderful convincing job of portraying the intelligent Nazi aristocrat, who had this ongoing obsession to take revenge on England. It was a true delight to see this kind of high quality performance in a youth series, but Ronald Leigh-Hunt was a good counterpart and the youngsters were so normal. They were very believable to me at the time and as a kid I could just imagine to be part of these youngsters, who at the time were about four years older than me. It was a very exciting series to me, standing out in my memory of those times as a special show with \"the Prisoner\" as well. I hope they will publish a good quality DVD of the series, that would be wonderful. Even the bad copies around are still enjoyable to watch. The later series were not as good, watered down and just not as much fun as the first three. Hopefully they also find the other series with Von Gelb to be put on DVD. Greetings from Canada.',\n",
              "         b'This is apparently one of Shemp\\'s first shorts with the Stooges. (This excludes his much earlier vaudeville years with the team). But the threesome\\'s comedic timing is at its honed best here. Aside from the intense slapstick scenes, there are others more subtle, but just as funny. Watch Larry when Shemp asks him to look at the camera for a snapshot. Or watch the real object prompting Moe\\'s exclamation, \"Oh...highly polished mahogany!\"<br /><br />Emil Sitka is at his bewildered goofiest. And the goon may look scary, but he\\'s somehow funny. He seems as frustrated and perplexed with the Stooges as are \"regular\" people in other shorts.<br /><br />For Shemp aficionados, this is a must have episode. It won\\'t disappoint.',\n",
              "         b\"I love this show! It's like watching a mini movie each week!!! The first episode was so gripping and terrifying...so was part 2 of the pilot... I'm definitely gonna keep tuning into this show! This is the real Survivor! I've looked at a few of the other comments and I can see that already after just one or two episodes the morons here are already crying wolf... Sorry if it's not another reality show, kiddies! There was once a time where there were...now brace yourself! Actual TV shows! And this one is actually good unlike most of the crappy sitcoms today or the ump-teenth carbon copy of a Law & Order or NYPD Blue or CSI series they're dishing out... Watch this yourself to form your own opinion, don't take one from the boneheads here!\",\n",
              "         b'As B movies go, it was well above average (I warn the reader now that I may reveal certain key elements of the plot or other parts of the movie, although I am trying to minimise any such tendency). As sequels usually go, it was utterly fantastic(despite a \"cookie cutter\" approach to trying to copy certain elements from the original movie verbatum. Despite this sometimes tedious tendency, it seemed to work in this particular film, so long as the viewer could divorce his attention from comparisons to the original \"Scanners\").<br /><br />The movie was similar in ways to the \"Superman\" series, in terms of the main character\\'s description of his early childhood and relationship with his parents (who seemed modelled along the same lines as the Kents in the \"Superman\" stories) and the theme of a morally pure hero possessed of extraordinary powers from an early age, etc. The depiction of profound feelings of alienation of prodigious or otherwise non-conforming children, adolescents and/or adults was a theme which reminded me of films such as \"Real Genius\", and (to a more superficial degree) \"Doctor Mordrid\" and struck a particularly strong chord.<br /><br />The film had a positive message, and was fun to watch. I found some of the insights and accuracy (in terms of depiction of certain aspects of paranormal experiences) fascinating, and even profoundly touching at times. These moments occasionally appeared from among all of the great formula-driven schlock and gratuitous sex(uality, in this case, as the sexual elements were tastefully done) and violence that makes B movies (or Shakespearian plays, for that matter!) so much fun to watch!<br /><br />This is a must watch for all comic book, Sci-fi, \"remote viewing\" enthusiasts, and horror fans! With the right exposure in the right circles, the film could develop quite a cult following, along with the original \"Scanners\".',\n",
              "         b\"Best animated movie ever made. This film explores not only the vast world of modern animation with absolutely boggling effects, but the branches of the human mind, soul, and philosophy. The story features a family of cats, where in the big sister dies, the younger brother sees this and rescues her body, but when she awakens she is left without a soul. So, the two sibling cats embark on a journey to find it. I have related this journey to many things. The history of the world, the bible, the cycle of life, and every time I watch it I discover more and more hidden themes and metaphors. If you aren't so into the physiological aspect of it then, you will still adore it. The animation is superb, and the creative scenes will have you attached to the screen. For example, the ocean freezing in time, god eating soup out of the earth, a strange and slightly SNM retelling of Hansel and Gretel. To conclude, Cat Soup is an absolute treat for anyone.<br /><br />PS- Not for kids, gratuitous violence included.\",\n",
              "         b'I was p***ed when I couldn\\'t see this one when it was screening at the Philly Film Fest last year, so when I saw that it was going to be on cable tonight, I put it on remind as soon as I could. So was it worth the wait? Well let\\'s backtrack a tad as I have yet to give you the plot. Sean Crawley is a young man who doesn\\'t know what his path in life is. Enter Duke (George Wendt) who introduces him to his boss Ray (Danny Baldwin). One night Ray totally hammered asks Sean to off the guy that they had Sean following around. And it goes on from there. Which leads me back to the question posed. Was it worth the wait? Yes and no, the buildup was pretty good and George Wendt stole the movie for me. He just took the ball and ran with it. But it\\'s nowhere near as violent as I was led to believe and somewhere along the movies running time the ball is not only dropped, but fumbled and taken in the other direction. I know where this point happened exactly, but can\\'t say without spoiling the film. But needless to say it happened. The ending doesn\\'t save the film either. Poor Stuart Gordon nothing can be good like \"Re-animator\" or \"Castle Freak\".<br /><br />My Grade: C<br /><br />Where I saw it: Showtime Extreme<br /><br />Eye Candy: Kari Wuhrer shows her ta-tas in one fantasy and then in the next more ta-tas and it pans down and...OH MY GOD MY EYES MY EYES!!!!!',\n",
              "         b'When teenagers go on a trip in a camper van there are many clich\\xc3\\xa9s that you can guarantee will follow.<br /><br />1)The teenagers will be warned not to go where they are going by a crazy local. Dan Van Husen handles that with ridiculous exposition about deadly Sirens. What, who, how and why are handled in one almost unintelligible burst. 2)The van will break down. 3)Whilst looking for help the group will be split up and be picked off one by one by whatever monster they have been warned about.4)They will find a house inhabited by a madman, he will capture them. 5) The house will have a phone but it will not work, it will be disturbingly decorated, there will be flickering neon light, spiders and maggots. 6)The madman will catch them as they try to escape in a vehicle that won\\'t start (here the high speed getaway was to be made on a tractor). 7)The madman will be seemingly killed only to come back from the dead for a cheap, weak scare and will then be killed properly. 8)Only a girl will be left alive from the group. 9)There will be an unnecessary twist at the end. <br /><br />Add to these elements naked Sirens (who the characters seem to react to in startling different ways despite the fact that everyone that sees them is supposed to fall into lust with them immediately) that seduce and kill the teens, throats being ripped out and bodies being pulled in half and you have something resembling a twelve year old boys dream movie.<br /><br />I think it is only fair to say that my opinion of the director and his previous work is as low as it is possible to be but I am happy to point out that there are a few elements that boarder on pleasurable and are a great improvement on his previous film, Darkhunters, which is one of the worst films I have ever seen. At times the cinematography is very good, the music and editing are a cut above his previous films and some other low budget horror movies. I was impressed to hear that it was achieved with a third of the money spent on the previous monstrosity. However, the worst things about this movie are not to be found in the body of the film, it is ultimately a mildly diverting if pointless movie that has been done time and time again, but amongst the DVD extras.<br /><br />If you do rent this film I implore you to listen to the director\\'s commentary it is beyond belief. There is more to say about this than the film itself. One staggering part of the commentary is the director\\'s claim that the film is clich\\xc3\\xa9 leaden because it was a preconceived idea. He says it is a deliberate attempt to use all of the clich\\xc3\\xa9s and openly he wonders if \"people will get it\". <br /><br />I\\'m afraid to say that if this is supposed to be a clever nod and a wink to films of the past and the genre clich\\xc3\\xa9s within them then it is not wittily scripted enough, acted in an appropriate tone nor directed with enough style to work. If this film was made to order it leads me to ask one question; \"What was the point?\" This is s afilm that just slips right into the canon of bad horror movies, any attempt to do something clever or different haven\\'t worked.<br /><br />The next nugget of brilliance is a conversation about the snobbery towards digital film formats. They rightly point out that digital is often synonymous with cheapness and ease of use. However, the best moment of the conversation comes when they bemoan the fact that when Michael Mann makes a film in the format he is branded as a visionary. There is a simple distinction to be made here; Mann is a talented director who will use the format to fit his story and style, Roberts is a horror hack who uses it to produce bottom shelf genre pictures . I think the differences are obvious and the comparison is not only arrogant but redundant.<br /><br />The best moment is reserved for Robert\\'s comments about people who have taken the time to review his previous film. Those who didn\\'t like it are generalised as \\'geeks\\' and he even goes as far as to single out specific people for having the nerve to voice their opinion in forums that encourage them to do just that. I must admit I was slightly disappointed that my review of his last film wasn\\'t singled out for ridicule. The tirade goes further as the group joke about Norwegian reviewers, complete with \\'hilarious\\' accents to imply that people from Norway wouldn\\'t know a good film simply because of where they are born. As always these sorts of comments say more about those saying them than those they are targeting, they simply make the director and his friends look ignorant.<br /><br />The package in rounded out with a tasteful featurette about how the Sirens were cast. Robert\\'s swears blind in voice over, \\'I didn\\'t want to make a film that was like Baywatch\\' as we see audition tapes of topless and naked girls writhing around on the ground. There is also a simpering, self-indulgent documentary about the making of Darkhunters during which Robert\\'s says that a reviewer has claimed that Forest is \"The best British film in years\". I don\\'t know who he is trying to convince. At one point in the commentary track Robert\\'s says jokingly \"I can see people sitting at home saying \"this isn\\'t amazing, its sh$t\" he isn\\'t wrong.',\n",
              "         b'The only reason to see this movie is for a brilliant performance by Thom-Adcox Hernandez who is underused in the movie within the movie. As usual Tom Villard is good, too. Otherwise it\\'s c**p. The possesor doesn\\'t even exist how does he magically change the letters on the theatre marquee to spell out \"The Possessor\"? Lame.',\n",
              "         b\"Some people don't like the animation. Personally, I think the animation was quite remarkable given when this movie was done. There are lots of older cartoons that I just love. My problems with this movie are not the animation, but basically the way it was constructed. The characters are all just... well, goofy. And for this movie, they shouldn't be. Apparently, everyone in LOTR has a limping problem (for starters.) Just the way they acted in general annoyed me. My two sisters and I were laughing through most of this movie. I think that if many people had seen this before seeing the newer ones, they wouldn't have gone. I'm glad I rented this and didn't buy it. There are few movies that give me a headache. This was one of them. However, this isn't the worst movie I've ever seen, although it ranks up there. Or down there, depending on your view.\",\n",
              "         b'I have just read the lead comment for this film that is on the front page with the voting results and cast run down.<br /><br />Why is it that some people can not take a film for what it is supposed to be.<br /><br />This film is supposed to be a light hearted, tonge in cheek, family comedy, things to make the kids laugh and things for the adults, and that is exactly what this film does.<br /><br />I laughed my nuts off at this film, I thought Carey put in a great performance and the whole film (if watched at Christmas) really give you a bit of festive cheer<br /><br />So to all of you film reviewers stop trying to sound like film students and knock every film because it is not \"Taxi Driver\" or \"The Godfather\" and take films for what they are supposed to be, entertainment!!',\n",
              "         b'Never before have the motives of the producers of a motion picture been more transparent. Let\\'s see: FIRST, they get every willing televangelist to hype this film as the greatest thing since sliced white bread. NEXT, they encourage as many fundamentalist Christians as possible to purchase copies of the film so as to recoup its paltry production costs and pump up its advertising budget. And FINALLY, when the film hits the theaters, get as many said Christians as possible to see it yet again, bus them into the multiplexes if necessary, NOT on the merits of the film itself, but because a #1 box office opening will be seen as some sort of profound spiritual victory.<br /><br />But THAT, of course, won\\'t be enough. I imagine that any film critic with the audacity to give \"Left Behind\" anything short of a glowing review will be deemed \"anti-Christian.\"<br /><br />Of course, this shamelessly manipulative marketing campaign shouldn\\'t surprise anyone. It is, after all, good old fashioned Capitalism at work. What DOES surprise me is how many people have been suckered into the whole \"Left Behind\" mindset. As someone who tries to balance his spiritual beliefs with some sense of reason and rationality, it leaves me scratching my head. It would appear that there are many, MANY people who actually believe that sometime in the near future a \"Rapture\" is going to occur, and that millions of people all over the Earth are going to simultaneously vanish INTO THIN AIR. What kind of reality, I wonder, are these people living in? Is this \"Rapture\" something they actually believe in, or is it something they fervently WANT to believe in? And when they reach the end of their lives and realize this \"Rapture\" has not occurred, will they be disappointed and disillusioned? Will there still be people 100 years from now insisting that the \"Rapture\" is imminent?<br /><br />In a way, I almost wish that such an event would occur! What an interesting day that would be! What would be even more interesting is if the Apocalypse were to occur in a more spectacular fashion, not in the anthropological sense the authors of the \"Left Behind\" series have portrayed, but as more of a Stephen Spielberg production, with boiling clouds, trumpets, angels descending out of the sky, Moon turned to blood, the whole nine yards. Imagine coming to the realization that it was all coming true, just as the evangelists had been warning for years, and that there was something more awesome than just the cold, hard, physical reality we inhabit. Wouldn\\'t THAT be something???<br /><br />Yet in the final analysis, it\\'s that cold, hard, physical reality that I will content myself with. My life is not so meaningless that I need the fear of a \"Rapture\" and the \"End Times\" to make sense of it all ... nor do I need Heaven or Hell to bribe or scare me into behaving decently, thank you very much.',\n",
              "         b'This movie is a mess, but at least it\\'s not pretentious. The box art for the video markets it as a \"fun throwback\" to 1950s giant bug movies. In reality, it\\'s a transparent bargain basement ripoff of \"Aliens\".<br /><br />The producers clearly wanted to make an \"ALIEN\" picture, but they mustn\\'t have had much money. In fact, it doesn\\'t look like they had ANY money, really. I hope everyone got paid who worked on this thing.<br /><br />The basic plot is retained--group of people isolated with murderous insectoid creature--and an earthbound location is inserted for budgetary reasons, I presume. Instead of setting the film in space, where no one can hear you scream, they set the film in a hospital, where everyone can see your budget laid bare. The amusing thing about \"Blue Monkey\" (and there is only one thing amusing about it) is, the filmmakers didn\\'t abandon the \"ALIEN\" aesthetics. Even though we\\'re in a hospital, we still have an improbably cavernous annex where science fiction experiments are being conducted, in this case the venerable \"growth hormone\" plot device. The annex also doubles as a boiler room (or something), so we can have an explanation for the monster seeking out the warmth. The boiler room is so large that it is laced with multi-leveled steel catwalks, perfect for allowing slime to drip down between the slats.<br /><br />The idea is that a man working in a greenhouse is attacked by a drooping flower from a rare imported plant that grows in an exotic location. He touches it and says \"Ow\", so we know he\\'s been hurt. The cut on his finger causes him to lapse into unconsciousness in a matter of minutes, and at the hospital he gives birth to a white worm through his mouth (I guess in an \"ALIEN\" picture this would be called the \"mouthburster\"?). The worm is isolated, but some naughty little kids (leukemia patients) sneak up on it and \"accidentally\" give it some experimental growth hormone. You know everyone\\'s in trouble when some fornicating hospital staff workers are attacked by a camera on a crane, and pretty soon a maintenance man finds some obligatory cocoons, right before he\\'s grabbed by a pair of semi-convincing insectoid arms. The rest of the movie is dominated by the semi-offscreen monster, semi-obscured by the semi-darkness.<br /><br />Which brings us back to \"ALIEN\". How, you ask, can a movie set in a hospital incorporate all those flashing strobe lights that are always in the \"ALIEN\" movies? No problem...a power outage (or something) causes the electrical system to go awry, which apparently causes strobe lights to blossom in every room of the hospital and flicker constantly throughout the movie. This doubles as a convenient cloak for the less-than-special effects (although the bugs are pretty neat looking, they don\\'t move too well, and the baby bug looks charmingly like a Cootie toy).<br /><br />OK, so what \"ALIEN\" bases haven\\'t we covered...OH, water dripping down the walls! Check...we\\'ll divide the massive hospital into two parts, then send some of the characters through the damp, drippy basement to get to the other side. Problem solved, we now have the opportunity for numerous \"foreboding tunnel\" shots. And don\\'t forget the fog...well, you never really need an excuse for this in horror movies, do you? OK, maybe inside of a hospital you do, so we\\'ll create smoke by having lots of things spark & burn.<br /><br />I haven\\'t said anything about the negligible acting, not that the actors are given any kind of script to follow. I take it \"Blue Monkey\" was supposed to be lighthearted and fun, and if so then it is a nice try, but the pieces don\\'t come together and the movie ends up being a real drag. See a film called \"Return of the Aliens: The Deadly Spawn\" if you want to see a film of this type that gets it right, with even less money and even more marginal acting talent. This one falls flat on its ALIEN.',\n",
              "         b'Usually, I know after the first minute of a movie if I will hate it or adore it... but now, I was wrong.<br /><br />The start was great; the \"this is based on a true story\" and blah blah blah thing was funny. After, the cartoons and the description of the guys\\' life with pictures made me think I had made the right choice.<br /><br />Then, seeing the hilarious fake look of Toronto was cool. Also, the situation and appearance of the house seemed to confirm my first idea.<br /><br />That was maybe the first 10 minutes of the movie... which afterwards looked like an eternity.<br /><br />Maybe that\\'s just me not understanding English Canadian humour (that\\'s possible, English Canadians also do not always understand Quebecois humour), but hey... there was enough stuff in that for a short movie, *nothing* more. Maybe that could be a meaning for the title? Anyway, almost everything was filling, and very few things were even close to funny in my opinion.<br /><br />As a matter of fact, the \"making of\" was better than the movie. At least you understand the motivation behind that which made everything bad. The potential of the idea was great; that\\'s why I rented the movie, being interested in the \"annoying people disappearance\" thing. But yet, I did not know the whole universe would vanish, and with it even a point to the movie.<br /><br />If you are English Canadian, it seems you could appreciate the local humour, considering the surprising number of people who gave this movie an 8. Otherwise, just think twice before losing your precious time...',\n",
              "         b'It is no surprise that writer/director Michael Powell considered \"A Matter of Life and Death,\" his and Emeric Pressburger\\'s spellbinding fantasy from 1946 to be his favourite of their films together. Released during the aftermath of World War 2, this colourful romantic adventure would have provided just the tonic for a traumatised, recovering nation in need of a good uplift.<br /><br />Following a string of other patriotic war films, \\'The Archers\\' made this one their quirkiest, skittish and most patriotic of the lot. Quintessentially British for upholding British heritage (Shakespeare, beer, fair play, good manners), it is also visibly Americanised in its baroque compositions, technical inventiveness and a fine multi-ethnic cast.<br /><br />Oddly echoing another 1946 classic, \"It\\'s a Wonderful Life,\" AMOLAD opens on a grand firmament, with one of those jolly voice-overs preaching about the earth and the heavens, and what a big, wonderful world we live in. <br /><br />It then cuts to the inside of a British cockpit, badly hit, up in flames and with the co-pilot already dead. It sounds misconceived, but the connection is soon made lucid with the events that follow.<br /><br />Clocking in at nearly 5 minutes, the rapid-fire exchange between British pilot Peter (David Niven) and American radio contact June (Kim Hunter) is breathtaking in its intimacy. Resigned to dying, Peter nevertheless exhausts plenty of vigour, charm and outpouring confessions, and his warm affiliation with June closes with a mutual exchange of \\'I love you.\\' <br /><br />Keeping with the magic of the moment, Peter, by oversight of his Conductor 71 whose job it was to transport him to the \\'Other World,\\' escapes death and finds himself stranded on a beach. He later encounters June riding a bicycle, and instantly matches the body with the voice. <br /><br />But realising their error, the high court want Peter sent back, and order the French Conductor (Maurice Goring) down to earth to retrieve him. But Peter is adamant to live because of June and the Conductor\\'s mistake, and wilfully guards his corner.<br /><br />Peter\\'s fate ultimately lies with the heavenly court and American prosecutor (Raymond Massey), whose jury consists of several deceased war heroes and posh British delegates. The surreal trial, which dissolves from b/w back into rich Technicolor, once the verdict is announced, may well be a dream, but the final shot in the hospital validates the predictable outcome.<br /><br />The abstract, frame filling \"stairway to heaven\" (the American title of the film) is used twice: the first time in b/w, when it elevates Peter and his enigmatic French guardian upwards, crossing giant statues of Peter\\'s potential attorneys for the trial, including Abraham Lincoln and Plato. The second time, the softly lit colour stairway provides the setting for what is an iconic image in cinema - Peter and June frozen side-by-side, their marvelled eyes fixed forward in the frame, their fate sealed.<br /><br />The unlikely affection shared between Peter and June never turns mushy or verbose; it\\'s treated with nobility and the perception that the couple are already suitable enough to be married and simply need to convince people of their love, so it can keep them together. <br /><br />The French Conductor, who can freeze time and people\\'s bodies, obtrudes many of their key moments together, lecturing Peter about history and among his mischievous tricks, pinching Peter\\'s \\'Top 100 Game Tricks\\' book and his coffee cup.<br /><br />As visually inspired as other Powell/Pressburger collaborations, this was the first time they combined colour with b/w \\xc2\\x96 the latter having a cheerful quality when used for the heaven scenes, and both are equally captivating. <br /><br />The outstanding script more than matches the imaginative set design, with dialogue that sounds so immediate that is doesn\\'t feel like it was written or performed for the screen. Amusing and witty, Powell/Pressburger\\'s writing deserves equal acclamation with their forte for colour and composition.<br /><br />Made in 1946, \"A Matter of Life and Death\" is one of those films that defies it age, looking fresh and inventive, even in this age where CGI would vamp up its artificial effects, probably stripping them of their emotional wonder. <br /><br />Other jarring changes would include the need for reduced average seconds for cutting and the inevitable plea to shorten dialogue so it can preserve the low attention spans of most audiences. Powell weaves a spell that subconsciously absorbs the viewer from the first frame, giving him freedom to experiment with images without betraying the logical development of Peter\\'s predicament.',\n",
              "         b\"Certainly one of the dozen or so worst movies ever released in any form, featuring a bizarrely abominable performance by Rain Joan of Arc Phoenix (River's sister, inevitably), as Bonanza Jellybean plus inconceivably awful voiceover narration by Tom Robbins, the author of the novel, which had/retains its peculiar sweet/loopy charms.\",\n",
              "         b\"1st watched 12/7/2002 - 3 out of 10(Dir-Steve Purcell): Typical Mary Kate & Ashley fare with a few more kisses. It looks to me like the girls are getting pretty tired of this stuff and it will be interesting what happens to them if they ever decide to split up and go there own ways. In this episode of their adventures they are interns in Rome for a `fashion' designer who puts them right into the mailroom to learn what working hard is all about(I guess..). Besides the typical flirtations with boys there is nothing much else except the Rome scenario until about \\xc2\\xbe way into the movie when it's finally revealed why they are getting fired, then re-hired, then fired again, then re-hired again. This is definetly made by people who don't understand the corporate world and it shows in their interpretation of it. Maybe the real world will be their next adventure(if there is one.). Even my kids didn't seem to care for this boring `adventure' in the make-believe. Let's see they probably only have a couple of years till their legal adults. We'll see what happens then.\",\n",
              "         b'Dev Anand (or Prashant) and Zeenat Aman ( Jasbir/Janice) are siblings brought up in single parent families. Jasbir (the sister) grows up in an affluent environment but this is not enough to lead her to reject her life and ultimately join a hippie movement that eventually leads her to drugs. Prashant (the brother) on the other hand grows up in a less affluent environment but grows up to be a matured gentleman. The story marks Prashant making efforts to save his little sister (who is perpetually in a trance) from a hostile hippie environment. This movie stands the test of time, commenting that cults and hippie groups are a place for those who give up on their lives when they should instead stand up and be counted in the face of adversity. Great music compositions in this movie that mean different things in different situations and to different people, and the director brings forth an eerie feeling to it.',\n",
              "         b\"I think that the shots and lighting were very poor. When I watched it for the first time I thought it was the old version(1956). When I really found out the true year of the film I was shocked. I didn't know that there could be such a bad film made so recently. Thats really all I wanted to say. This film had a good plot though, nothing you couldn't miss out on if you would simply read the novel that George Orwelll wrote. All I really want to say has already been said except for this: I can't believe that this film could have possibly received so many awards and nominations.I gave this film a One (awful), because I felt that it was very badly made. Well that is all. So long\"],\n",
              "        dtype=object)>,\n",
              "  <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              "  array([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 1, 0, 0, 0, 1, 0, 0, 1, 0], dtype=int32)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 20000, 5000, and 25000 records in train, validation, and test directories with two class as positive and negative."
      ],
      "metadata": {
        "id": "GDg21guTV5K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shapes\n",
        "\n",
        "for inputs, targets in train_ds:\n",
        "\n",
        "    print(\"inputs.shape:\", inputs.shape)\n",
        "    print(\"inputs.dtype:\", inputs.dtype)\n",
        "\n",
        "    print(\"targets.shape:\", targets.shape)\n",
        "    print(\"targets.dtype:\", targets.dtype)\n",
        "\n",
        "    print(\"inputs[2]:\", inputs[2])\n",
        "    print(\"targets[2]:\", targets[2])\n",
        "\n",
        "    break"
      ],
      "metadata": {
        "id": "ky7BB3qtV5K9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78be8995-eab1-47dc-876d-16680129ced1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs.shape: (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[2]: tf.Tensor(b\"Johny To makes here one of his best style exercises, making a strong film with a good Yakuza's story. The election of the new Yakuza's boss is the beginning of a war inside the organization.<br /><br />In my opinion the violence is wise used in the context, making a very strong gangs film. I specially love the way he tells the history, moving around all the roles inside the Yakuza's family, and making that we see the violence, like the only way they have to solve their problems...<br /><br />Talking about, the technical aspects, the film is a good example of paused, rythmic and planified way of shooting a film. One of the Hong Kong Films of the year. Is like Infernal affairs, but without the easy action-violence scenes, and the confused storyline. Strongly recommended to all Asian films lovers.<br /><br />(sorry for my English, better do in Spanish lol)\", shape=(), dtype=string)\n",
            "targets[2]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create TextVectorization layer and adapt to dataset"
      ],
      "metadata": {
        "id": "cZBJ4FHmV5K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing the data\n",
        "#Only valid in INT mode. If set, the output will have its time dimension padded or truncated to exactly\n",
        "#output_sequence_length values, resulting in a tensor of shape (batch_size, output_sequence_length)\n",
        "\n",
        "max_length = 600 # Output length of the sequence output padded if length of out is less\n",
        "max_tokens = 20000 #when using adapt, what is the vocab size to be built\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,    # Q: What is the vocabular size?\n",
        "    output_mode=\"int\",        # Q: What will be the type of output for a token (say), 'amazing' ?\n",
        "    output_sequence_length=max_length,      # Q: What is the maximum length of review? Is it a fair assumption?\n",
        "    )\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n"
      ],
      "metadata": {
        "id": "5lOfI18GV5K9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOrcxQtSrtNS",
        "outputId": "5f5a284d-ccbb-4213-eb5d-087606b69ef5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'a', 'and', 'of', 'to', 'is', 'in', 'it']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_vectorization.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSPtPsVGwxFH",
        "outputId": "2f6fcfa1-0aaa-4c76-f798-266854826d5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization('The film was good and it had a lot of action scenes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehkIYX05rziq",
        "outputId": "b1be0e2e-394d-4d46-ebf3-29ffaca493da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(600,), dtype=int64, numpy=\n",
              "array([  2,  20,  14,  50,   4,   9,  67,   3, 169,   5, 214, 137,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Part B** : Building Encoder Transformer"
      ],
      "metadata": {
        "id": "L4lbyeZVxojj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure below shows the **Transformer Model Architecture** as per the paper [\"**Attention Is All You Need**\"](https://arxiv.org/pdf/1706.03762v6.pdf) .Here, we are going to implement **Encoder** and try to understand how it function. We are writing **'as per the paper'** to  mention this paper throughout this notebook. To completely understand the Encoder Transformer, it is imperative to understand Self Attention which is used inside Multi-head Attention. The data after passing the TextVectorization layer and Embedding layer will pass the Self Attention layer.\n",
        "<br><br>\n",
        "<center>\n",
        "<img src= \"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data/Images/Transformer.png\" width=750px/>\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "xEAlgHlEi360"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention\n",
        "The attention mechanism being depicted in the picture below can be understood as the attention scores highlighting the most important features of the cat so that it can be identified."
      ],
      "metadata": {
        "id": "OoxkpGwjLs8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<center>\n",
        "<img src= \"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/Attention%20scores%20pic.png\" width=700px/>\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "hXf1hMTsaybL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the popular language models does not have just the term 'BERT' in their name but an important techique called 'self-attention'. Transformer-based architectures, which are primarily used in modelling language understanding tasks, eschew recurrence in neural networks and instead trust entirely on self-attention mechanisms to draw global dependencies between inputs and outputs."
      ],
      "metadata": {
        "id": "9WM_eM6KLGSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src= \"https://cdn.iisc.talentsprint.com/AIandMLOps/Images/M5%20AST5%20Self%20Attention%20Scores.png\" width=900px/>\n",
        "</center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_nEW1yj8Gzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "outputs = sum(inputs * pairwise_scores(inputs, inputs))\n"
      ],
      "metadata": {
        "id": "3wTkPQOSJ7VJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the self attention scores which are depicted in the picture, the word 'train pays' more attention to station rather than other words in consideration such as 'on' or the."
      ],
      "metadata": {
        "id": "tC2wZV8FNpuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The attention mechanism allows output to focus attention on input while producing output while the self-attention model allows inputs to interact with each other (i.e calculate attention of all other inputs wrt one input)."
      ],
      "metadata": {
        "id": "qOp6pGTsNnP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Inside each attention head is a **Scaled Dot Product Self-Attention** operation, the operation returns a Attention vector as given by equation below:\n",
        "\n",
        "$$ Self Attention = softmax(\\frac{x^{T}_i x_j}{\\sqrt{d_k}})x_j $$\n",
        "\n",
        "The term  **$x^{T}_i x_j$** is dot product of input vector with itself. The  'pivot_vector' and the 'vector' forms the 'xi' and 'xj' of the above Self Attention function."
      ],
      "metadata": {
        "id": "gFRVERe-bRFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demonstrating self_attention with dummy data"
      ],
      "metadata": {
        "id": "y5OQMPqTOGRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define a custom self attention function"
      ],
      "metadata": {
        "id": "weO9uy0NYcGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom self attention function\n",
        "def self_attention(input_sequence):\n",
        "    output = np.zeros(shape=input_sequence.shape)\n",
        "    for i, pivot_vector in enumerate(input_sequence): # iterate over each token in ip seq\n",
        "        scores = np.zeros(shape=(len(input_sequence), ))\n",
        "\n",
        "        for j, vector in enumerate(input_sequence):\n",
        "            scores[j] = np.dot(pivot_vector, vector.T)    # Pairwise scores\n",
        "\n",
        "        scores /= np.sqrt(input_sequence.shape[1]) # scale #[1] is the embedding dim\n",
        "        scores = tf.nn.softmax(scores)              # softmax\n",
        "        new_pivot_representation = np.zeros(shape=pivot_vector.shape)\n",
        "        for j, vector in enumerate(input_sequence):\n",
        "            new_pivot_representation += vector*scores[j] # weigthed sum\n",
        "        output[i] = new_pivot_representation\n",
        "    return output\n",
        "\n",
        "# Optional HW: Add to the code to print the attention_score matrix"
      ],
      "metadata": {
        "id": "kUpa5Baeyrlz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use a dummy data and find its vectors"
      ],
      "metadata": {
        "id": "qf8cvT-qYoDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data first passes through the TextVectorization layer then through the Embedding layer and later the Self Attention scores are calculated"
      ],
      "metadata": {
        "id": "__9n0HmEZBoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, vectorize raw text using _________\n",
        "dummy_vocab = [\"movie was very nice\", \"film was good\"]\n",
        "text_vec = layers.TextVectorization(max_tokens=5, output_sequence_length=3)\n",
        "text_vec.adapt(dummy_vocab)\n",
        "print(text_vec(\"movie\"))\n",
        "#Q: why the zeros ? why shape 3?\n",
        "#Q: output type?"
      ],
      "metadata": {
        "id": "KjBz5gZ_qxrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb739fa-9983-435d-ce0c-144d8dc44596"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 0 0], shape=(3,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then obtain embeddings from text indices using the Embedding layer\n",
        "int_text = text_vec([\"movie was good\"])\n",
        "print(int_text)\n",
        "embedding = layers.Embedding(input_dim=5, output_dim=4)(int_text)  # Why 5 ? input_dim: Integer. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "print(embedding)"
      ],
      "metadata": {
        "id": "FBVu6T8KSFVg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b458532f-d722-40f3-a5f9-e50cb1ac4080"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[1 2 1]], shape=(1, 3), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[[ 0.01905343 -0.00803129  0.02016748 -0.03094834]\n",
            "  [ 0.03039265  0.04239618  0.01108522 -0.00826528]\n",
            "  [ 0.01905343 -0.00803129  0.02016748 -0.03094834]]], shape=(1, 3, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Output from the attention function"
      ],
      "metadata": {
        "id": "h73JajZDY0xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute output of attention module\n",
        "attention_outputs = self_attention(embedding[0].numpy())\n",
        "print(attention_outputs.shape)\n",
        "print(attention_outputs)"
      ],
      "metadata": {
        "id": "9Orj9lkLqxuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d70e33a-ca62-4b67-c85e-f45bf637787a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 4)\n",
            "[[ 0.02283182  0.00877185  0.01714115 -0.02339003]\n",
            " [ 0.02283594  0.00879017  0.01713785 -0.02338179]\n",
            " [ 0.02283182  0.00877185  0.01714115 -0.02339003]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention Eqn. with Queries, Keys and Values\n",
        "\n",
        "We computed the Self Attention based on the inputs of vectors themselves. This means that for fixed inputs, these attention weights would always be fixed. In other words, there are no learnable parameters. Need to introduce some learnable parmeters which will make the self attention mechanism more flexible and tunable for various tasks. To fullfil this purpose, three weight matices are introduced and multiplied with input $x_i$ seperately and three new terms **Queries(Q), Keys(K) and Values(V)** comes into picture as given by equations below. Vectorized implemenation  & Shape tracking are also shown along with equations."
      ],
      "metadata": {
        "id": "xEFymWCLeAQ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vectorized implemenation  & Shape tracking**\n",
        "\n",
        "$ d_{model} $ = Embedding vector for each word ( 512 as per the paper).\n",
        "\n",
        "$ X   \\Rightarrow (T \\times d_{model}) $\n",
        "\n",
        "\n",
        "$ Q = X W^{Q}   \\Rightarrow (T \\times d_{model}) \\times (d_{model} \\times d_k  )  \\Rightarrow   (T \\times d_{k}) $\n",
        "\n",
        "\n",
        "$ K = X W^{K}   \\Rightarrow (T \\times d_{model}) \\times (d_{model} \\times d_k  )  \\Rightarrow   (T \\times d_{k}) $\n",
        "\n",
        "\n",
        "$ V = X W^{V}   \\Rightarrow (T \\times d_{model}) \\times (d_{model} \\times d_v  )  \\Rightarrow   (T \\times d_{v}) $\n",
        "\n",
        "Dot product of Queries and Keys:\n",
        "\n",
        "$ Q K^{T}   \\Rightarrow (T \\times d_{k}) \\times (d_{k} \\times T  )  \\Rightarrow   (T \\times T) $\n",
        "\n",
        "T query vectors and T key vectors (Input Sequence), so need TxT attention weights. Make Sense! Taking SoftMax doesn't change the shape.\n",
        "\n",
        " **Shapes as per the paper**\n",
        "\n",
        "$\n",
        "\\begin{array}{|c|c|} \\hline\n",
        "Object   &  Shape & values  \\\\ \\hline\n",
        "q_i, k_i  &  d_k  &  (64,) \\\\\n",
        "v_i   &   d_v   &   (64,)  \\\\\n",
        "x_i   &   d_{model}   & (512,)  \\\\\n",
        "W^{Q}, W^{K}  &   d_{model} \\times d_k   &   (512, 64)  \\\\\n",
        "W^{V}   &   d_{model} \\times d_v   &  (512,64)  \\\\ \\hline\n",
        "\\end{array}\n",
        "$\n",
        "\n",
        "**Batch consideration**\n",
        "\n",
        "In code, a batch of N samples are processed at a time. Everyting would be  **N times**, like: $ N \\times T \\times d_k $ instead of just $ T \\times d_k$."
      ],
      "metadata": {
        "id": "nEqmUxkDf-fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Fianl Scaled Dot Product Attention** equation inside each attention head with **Queries(Q)**, **Keys(Q)**, and **Values(V)**, which returns a Attention vector.\n",
        "\n",
        "<center>\n",
        "<img src= \"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data/Images/Scaled_dot_product_Attention.png\" width=250px/>\n",
        "\n",
        "</center>\n",
        "\n",
        "\n",
        "$$Attention(Q, K, V) = softmax(\\frac{QK^T)}{\\sqrt{d_k}})V$$"
      ],
      "metadata": {
        "id": "OHr_TAfbgdig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multihead Attention"
      ],
      "metadata": {
        "id": "6PVKxy5PcCYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the output of the final Encoder in the stack is passed to the Value and Key parameters in the Encoder-Decoder Attention.\n",
        "\n",
        "The Encoder-Decoder Attention is therefore getting a representation of both the target sequence (from the Decoder Self-Attention) and a representation of the input sequence (from the Encoder stack). It, therefore, produces a representation with the attention scores for each target sequence word that captures the influence of the attention scores from the input sequence as well.\n",
        "\n",
        "As this passes through all the Decoders in the stack, each Self-Attention and each Encoder-Decoder Attention also add their own attention scores into each word’s representation."
      ],
      "metadata": {
        "id": "yLiXoAWEaQS7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Transformer, the Attention module repeats its computations multiple times in parallel. Each of these is called an Attention Head. The Attention module splits its Query, Key, and Value parameters N-ways and passes each split independently through a separate Head. All of these similar Attention calculations are then combined together to produce a final Attention score. This is called Multi-head attention and gives the Transformer greater power to encode multiple relationships and nuances for each word."
      ],
      "metadata": {
        "id": "xzQy3FMLaj8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the paper, the diagram for a scaled dot product attention does not use any weights at all. Instead, the weights are included only in the multi head attention block, shown in figure below :\n",
        "<br><br>\n",
        "<center>\n",
        "<img src= \"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data/Images/Multi_head_attention_with_weights.png\" width=900px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "xgX4dIqzalYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the shape\n",
        "<br>\n",
        "<center>\n",
        "<img src= \"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data/Images/Multi_head_attention_shape_tracking.png\" width=750px>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "**Final Projection :** $ Output = concat(A_1, A_2, ..., A_h)  W^{o} $\n",
        "\n",
        "**Shape of :**  $ concat (A_1, A_2, ..., A_h) \\Rightarrow  (T \\times hd_v) $\n",
        "\n",
        "**Shape of:**  $  W^{o} \\Rightarrow (hd_v \\times d_{model}) $\n",
        "\n",
        "**Shape of final:**  $ Ouput = concat (A_1, A_2, ..., A_h) W^{o} \\Rightarrow  (T \\times hd_v) \\times (hd_v \\times d_{model})  \\Rightarrow  (T \\times d_{model}) \\Leftarrow $ **Back to the initial input shape.**\n",
        "\n",
        "Batch size is not displayed here."
      ],
      "metadata": {
        "id": "QydYglmilY9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Encoder Block\n",
        "\n",
        "The Transformer Encoder consists of a stack of\n",
        " identical layers (Encoder Block) as shown in figure below, where each layer further consists of two main sub-layers:\n",
        "\n",
        "* The first sub-layer comprises a multi-head attention mechanism that receives the queries, keys, and values as inputs.\n",
        "* A second sub-layer comprises a fully-connected feed-forward network.\n",
        "\n",
        "Following each of these two sub-layers is layer normalization, into which the sub-layer input (through a residual/skip connection) and output are fed.\n",
        "\n",
        "Regularization is also intrpduced into the model by applying a dropout to the output of each sub-layer (before the layer normalization step), as well as to the positional encodings before these are fed into the encoder.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src=\"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data//Images/Encoder_tfr_block_unfolded.png\"  width=600 px />$⇒$\n",
        "<img src=\"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data/Images/Encoder_tfr_block.png\" width=180 px/>\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "9ei6127oCBQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transformer encoder architecture typically consists of multiple layers, each of which includes a self-attention mechanism and a feed-forward neural network. The self-attention mechanism allows the model to weigh the importance of different input sequence parts by calculating the embeddings' dot product. This mechanism is also known as multi-head attention.\n",
        "\n",
        "The feed-forward network allows the model to extract higher-level features from the input. This network usually comprises two linear layers with a ReLU activation function in between. The feed-forward network allows the model to extract deeper meaning from the input data and more compactly and usefully represent the input.In the paper, an ANN with one hidden layer and a ReLu activation in the middle  with no activation function at output layer has been implemented.\n",
        "\n",
        "The transformer encoder is a crucial part of the transformer encoder-decoder architecture, which is widely used for natural language processing tasks."
      ],
      "metadata": {
        "id": "UU0hqgB0cz17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder Transformer\n",
        "Stacking transormer blocks gives a Transfomer! Shown in figure below:\n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src= \"https://cdn.extras.talentsprint.com/aiml/Experiment_related_data/Images/Encoder_transfomer.png\" width=1000px/>\n",
        "</center>"
      ],
      "metadata": {
        "id": "RWF4OyFonkHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define TransformerEncoder class"
      ],
      "metadata": {
        "id": "MxZdesd1dgAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim    # Dimension of embedding. 4 in the dummy example\n",
        "        self.dense_dim = dense_dim    # No. of neurons in dense layer\n",
        "        self.num_heads = num_heads    # No. of heads for MultiHead Attention layer\n",
        "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)    # MultiHead Attention layer\n",
        "        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                                            layers.Dense(embed_dim),]    # encoders are stacked on top of the other.\n",
        "                                           )                             # So output dimension is also embed_dim\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    # Call function based on figure above\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(query=inputs,             # Query: inputs,\n",
        "                                          value=inputs,             # Value: inputs,\n",
        "                                          key=inputs,               # Keys: Same as Values by default\n",
        "                                          attention_mask=mask\n",
        "                                          )                         # Q: Can you see how this is self attention? A: all args are the same\n",
        "\n",
        "        proj_input = self.layernorm_1(inputs + attention_output) # LayerNormalization; + Recall cat picture\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)  # LayerNormalization + Residual connection\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "loHOqli9qxza"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model definition"
      ],
      "metadata": {
        "id": "QX4opYwUdrtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Transformer encoder\n",
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorization(inputs)                                         # TextVectorization layer\n",
        "x = layers.Embedding(vocab_size, embed_dim)(x)                         # Embedding layer\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)             # Transformer Encoder block\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)                     # Dense layer for classification\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "61zmVZv8q4AO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "8dcc410e-3077-41fc-a265-c18798bb9818"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m5,120,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m543,776\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,664,033\u001b[0m (21.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,664,033</span> (21.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate the performance of the model *(Switch to GPU runtime if needed)*"
      ],
      "metadata": {
        "id": "RwJwGlMPdypN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on train set\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\", save_best_only=True)]\n",
        "\n",
        "# Change target shape from (None,) to (None, 1)\n",
        "train_dataset = train_ds.map(lambda x, y: (x, tf.reshape(y, (-1,1))))\n",
        "val_dataset = val_ds.map(lambda x, y: (x, tf.reshape(y, (-1,1))))\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          validation_data = val_dataset,\n",
        "          epochs = 10,\n",
        "          callbacks = callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i8NBr5m9rdI",
        "outputId": "f1575174-410b-4e74-ae07-00c9eacd234d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 69ms/step - accuracy: 0.5381 - loss: 0.8638 - val_accuracy: 0.8182 - val_loss: 0.4057\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 68ms/step - accuracy: 0.8142 - loss: 0.4175 - val_accuracy: 0.8502 - val_loss: 0.3490\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step - accuracy: 0.8429 - loss: 0.3557 - val_accuracy: 0.8644 - val_loss: 0.3263\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step - accuracy: 0.8639 - loss: 0.3236 - val_accuracy: 0.8728 - val_loss: 0.3083\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.8717 - loss: 0.2987 - val_accuracy: 0.8686 - val_loss: 0.3137\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 71ms/step - accuracy: 0.8854 - loss: 0.2723 - val_accuracy: 0.8740 - val_loss: 0.2997\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 71ms/step - accuracy: 0.8921 - loss: 0.2588 - val_accuracy: 0.8764 - val_loss: 0.2959\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 71ms/step - accuracy: 0.9041 - loss: 0.2339 - val_accuracy: 0.8750 - val_loss: 0.2995\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 70ms/step - accuracy: 0.9129 - loss: 0.2193 - val_accuracy: 0.8688 - val_loss: 0.3285\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - accuracy: 0.9224 - loss: 0.2032 - val_accuracy: 0.8702 - val_loss: 0.3295\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aac63f695a0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\n",
        "    \"transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder}\n",
        "    )\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "XBJAe2oA6ZeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17fc16f-9467-4315-a20b-ae30ce6029a7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.8706 - loss: 0.3047\n",
            "Test acc: 0.868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction"
      ],
      "metadata": {
        "id": "Y_ynmV4i8g9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"It was a great movie\"\n",
        "myTensor = tf.convert_to_tensor(txt, dtype=tf.string)\n",
        "print(myTensor)"
      ],
      "metadata": {
        "id": "dhIezy2J6x49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d622b144-7606-4eee-c09c-ce4dc3c3eba7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'It was a great movie', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(tf.reshape(myTensor, (-1,1)))\n",
        "pred"
      ],
      "metadata": {
        "id": "3ehCx9UC3AjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4568cbd-ec23-46d1-a603-1ce9ba3c7f31"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.930238]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_index = int(pred.numpy()[0,0] + 0.5)\n",
        "label_index"
      ],
      "metadata": {
        "id": "7km7x0S78KUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df729e3-8b2c-47cc-a4f7-f119a75746f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {0: 'Negative', 1: 'Positive'}\n",
        "label = mapping[label_index]\n",
        "label"
      ],
      "metadata": {
        "id": "28O5tOYa89c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "533ef5d8-43c8-4904-9129-cf7517e81c0d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(input_text, tf_model):\n",
        "    myTensor = tf.convert_to_tensor(input_text, dtype=tf.string)\n",
        "    pred = tf_model(tf.reshape(myTensor, (-1,1)))\n",
        "    label_index = int(pred.numpy()[0,0] + 0.5)\n",
        "    mapping = {0: 'Negative', 1: 'Positive'}\n",
        "    label = mapping[label_index]\n",
        "    return label"
      ],
      "metadata": {
        "id": "jAKnkAQbD-ZW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"It was a great movie\", model)"
      ],
      "metadata": {
        "id": "o71PtDijEoFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5c2da3c-1ed5-40cb-8819-752af808e3ba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"It was a bad movie\", model)"
      ],
      "metadata": {
        "id": "j4MaEkfjExD5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "758b881e-b7e2-466b-e439-9c6cb539096c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Embedding\n",
        "\n",
        "**Positional Embedding = Word Embedding + Positional Encoding**\n",
        "\n",
        "**Positional Encoding**\n",
        "\n",
        "Passing embeddings directly into the transformer block results in missing of information about the order of tokens. As attention is permutation invariant i.e. order of token does not matter to attention.\n",
        "Although transformers are a sequence model, it appears that this important detail has somehow been lost. Positional encoding is for rescue.\n",
        "\n",
        "Positional encoding add positional information to the existing embeddings.\n",
        "\n",
        "**A unique set of numbers added at each position of the existing embeddings**, such that this new set of numbers can uniquely identify which postion they are located at.\n",
        "\n",
        "\n",
        "1. Positional Encoding by SubClassing the Keras Embedding Layer (Trainable)\n",
        "2. Positional Encoding scheme as per the paper (Non-Trainable)\n",
        "\n",
        " In this scheme the encoding is created by using a set of sins and cosines at different frequencies. The  paper uses the following formula for calculating the positional encoding. [Positional Encoding Vizualization.](https://erdem.pl/2021/05/understanding-positional-encoding-in-transformers)\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})} $$\n",
        "\n",
        "We are going to implement Positional Encoding by SubClassing the Keras Embedding Layer (Trainable). Thus Instead of using the Embedding layer from keras define a PositionalEmbedding class and create a new model using it as the embedding layer."
      ],
      "metadata": {
        "id": "jFZ23Yzywtqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using positional encoding to re-inject order information\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):                  # input_dim = (token) vocabulary size,  output_dim = embedding size\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)            # Q: what is input_dim and output_dim? A: vocab size, embedding dim\n",
        "        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)   # Q: Why input_dim = seq_length?  A: there are seq_len; no. of possible positions\n",
        "                                                                                                        # Q: What is the vocab for this Embedding layer? A: seq_length\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "\n",
        "    def call(self, inputs):   # inputs will be a batch of sequences (batch, seq_len)\n",
        "        length = tf.shape(inputs)[-1]     # lenght will just be sequence length\n",
        "        positions = tf.range(start=0, limit=length, delta=1) # indices for input to positional embedding\n",
        "        embedded_tokens = tf.reshape(self.token_embeddings(inputs), (-1, length, self.output_dim))\n",
        "        embedded_positions = tf.reshape(self.position_embeddings(positions), (-1, length, self.output_dim))\n",
        "        return layers.Add()([embedded_tokens, embedded_positions])     # ADD the embeddings\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):     # makes this layer a mask-generating layer\n",
        "        if mask is None:\n",
        "            return None\n",
        "        return tf.math.not_equal(inputs, 0)        # mask will get propagated to the next layer.\n",
        "\n",
        "    # When using custom layers, this enables the layer to be reinstantiated from its config dict,\n",
        "    # which is useful during model saving and loading.\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "B1MVsKFZsVPh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does tf.math.not_equal() do?\n",
        "\n",
        "a = tf.constant([1,0,2,0,3]) # a is a tensor\n",
        "print(a)\n",
        "print(tf.math.not_equal(a, 0))   # which elements of 'a' are not equal to 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwDciZc2g3za",
        "outputId": "ff0d220d-42cc-480c-d92a-24a69f633fcd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 0 2 0 3], shape=(5,), dtype=int32)\n",
            "tf.Tensor([ True False  True False  True], shape=(5,), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Definition"
      ],
      "metadata": {
        "id": "ym7HzyaLeSrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Combining the Transformer encoder with positional embedding\n",
        "\n",
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorization(inputs)                                             # Text Vectorization layer\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(x)         # Embedding layer  +  Positional Encoding\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)                 # Transformer Encoder block\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)                         # Dense layer for classification\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BOFIwLWGsk_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "8abbc0dc-2e32-408b-8049-94554dbdf457"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_embedding                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m5,273,600\u001b[0m │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m543,776\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m257\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ positional_embedding                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,273,600</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_encoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">543,776</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,817,633\u001b[0m (22.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,817,633</span> (22.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,817,633\u001b[0m (22.19 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,817,633</span> (22.19 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and evaluate the model *(Switch to GPU runtime if needed)*"
      ],
      "metadata": {
        "id": "1_Ua8m85eWw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on train set\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\", save_best_only=True)]\n",
        "\n",
        "# Change target shape from (None,) to (None, 1)\n",
        "train_dataset = train_ds.map(lambda x, y: (x, tf.reshape(y, (-1,1))))\n",
        "val_dataset = val_ds.map(lambda x, y: (x, tf.reshape(y, (-1,1))))\n",
        "\n",
        "model.fit(train_dataset,\n",
        "          validation_data = val_dataset,\n",
        "          epochs = 10,\n",
        "          callbacks = callbacks)"
      ],
      "metadata": {
        "id": "07lwJKB09_hO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a69e34b-e5cb-432f-b363-cd5abc4cab28"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 72ms/step - accuracy: 0.5863 - loss: 0.8340 - val_accuracy: 0.8144 - val_loss: 0.4171\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 73ms/step - accuracy: 0.8014 - loss: 0.4350 - val_accuracy: 0.8214 - val_loss: 0.3899\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 75ms/step - accuracy: 0.8354 - loss: 0.3786 - val_accuracy: 0.8346 - val_loss: 0.3728\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 72ms/step - accuracy: 0.8487 - loss: 0.3430 - val_accuracy: 0.8482 - val_loss: 0.3512\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 72ms/step - accuracy: 0.8657 - loss: 0.3148 - val_accuracy: 0.8394 - val_loss: 0.3629\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 73ms/step - accuracy: 0.8890 - loss: 0.2749 - val_accuracy: 0.8510 - val_loss: 0.3474\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 72ms/step - accuracy: 0.9063 - loss: 0.2351 - val_accuracy: 0.8476 - val_loss: 0.3724\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.9236 - loss: 0.1978 - val_accuracy: 0.8520 - val_loss: 0.3790\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 72ms/step - accuracy: 0.9414 - loss: 0.1529 - val_accuracy: 0.8438 - val_loss: 0.4247\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 72ms/step - accuracy: 0.9586 - loss: 0.1190 - val_accuracy: 0.8204 - val_loss: 0.5191\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aac12156350>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\n",
        "    \"full_transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
        "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
        "\n",
        "print(f\"Test acc: {model.evaluate(test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "9Zc8-32U-M7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb696eb5-9b74-4628-f33a-630e034f67b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'positional_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'transformer_encoder_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8519 - loss: 0.3425\n",
            "Test acc: 0.850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction"
      ],
      "metadata": {
        "id": "VVRNXErL3o3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"It was a great movie\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JpX4gccL20Nv",
        "outputId": "0b83ae1e-768f-4e7c-e968-3eff9911372c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction(\"It was a bad movie\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OUpAJYRL3dVK",
        "outputId": "29a51fb4-9250-41ca-f5b7-d95d5d3c12f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "If you are very interested or plan to work closely on Transformers, then following are good resource that explains in simplified manner.\n",
        "\n",
        "1. [Attention Is All You Need](https://arxiv.org/pdf/1706.03762v6.pdf)\n",
        "\n",
        "2. [Understanding Positional  Encoding](https://erdem.pl/2021/05/understanding-positional-encoding-in-transformers)\n",
        "\n",
        "2. [Implement Multi-Head Attention](https://machinelearningmastery.com/how-to-implement-multi-head-attention-from-scratch-in-tensorflow-and-keras)\n",
        "\n",
        "3. [Implementing the Transformer Encoder](https://machinelearningmastery.com/implementing-the-transformer-encoder-from-scratch-in-tensorflow-and-keras/)\n",
        "\n",
        "4. [Illustrated-transformer](https://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "beX9CfsVI3on"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOC1n4C5dxsb"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6HQodIl8dxs1"
      },
      "outputs": [],
      "source": [
        "#@title Which layer in the Transformer model is responsible for capturing local dependencies within an input sequence? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer = \"Self-Attention Layer\" #@param [\"\", \"Self-Attention Layer\", \"Feedforward Neural Network Layer\", \"Positional Encoding Layer\", \"Layer Normalization\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "outputs": [],
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "outputs": [],
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"na\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "outputs": [],
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "outputs": [],
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "outputs": [],
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9962f8-1f92-4b86-ba02-c374f37e4ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 6349\n",
            "Date of submission:  26 Aug 2024\n",
            "Time of submission:  23:46:01\n",
            "View your submissions: https://aimlops-iisc.talentsprint.com/notebook_submissions\n"
          ]
        }
      ],
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ]
    }
  ]
}